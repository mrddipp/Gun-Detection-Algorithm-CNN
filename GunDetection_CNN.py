# -*- coding: utf-8 -*-
"""GunDetection_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-gs66NpnRU3z56pYK9Q2r5noToRc2AEa
"""

'''Importing the Libraries'''
import numpy as np
import tensorflow as tf
from tensorflow import keras
from keras.metrics import metrics
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, Activation, BatchNormalization
from keras import optimizers
from keras import regularizers
from keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import confusion_matrix, plot_confusion_matrix
import os
import cv2
import matplotlib.pyplot as plt
from google.colab import drive
drive.mount('/content/drive')

'''Importing the Data'''

datagen = ImageDataGenerator(rotation_range=25, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')

path_train_data = '/content/drive/Shareddrives/Machine Learning/projectguns/Data/train'
X_train = datagen.flow_from_directory(directory=path_train_data,color_mode='rgb', target_size=(100,100),classes=['gun_found','gun_not_found'], batch_size=10, shuffle=True)

path_valid_data = '/content/drive/Shareddrives/Machine Learning/projectguns/Data/valid'
X_valid = datagen.flow_from_directory(directory=path_valid_data,color_mode='rgb', target_size=(100,100),classes=['gun_found','gun_not_found'], batch_size=10, shuffle=True)

path_test_data = '/content/drive/Shareddrives/Machine Learning/projectguns/Data/test'
X_test = datagen.flow_from_directory(directory=path_test_data, color_mode='rgb', target_size=(100,100), classes=['gun_found','gun_not_found'], batch_size=10, shuffle=True)

''' Function for Visualization of the Data '''

def dispImage(array):
  fig1, ax = plt.subplots(1,10, figsize=(50,50))
  ax = ax.flatten()
  for img, ax in zip(array, ax):
    ax.imshow(img)
    ax.axis('off')
  plt.tight_layout()
  plt.show()


a,b = next(X_train)
dispImage(a)
print(b)

''' Machine Learning Model'''

# Creating the Model
model = Sequential(name='gun_CNN_classifier')

# Set of Layer-1 (Convolutional + MaxPooling)

model.add(Conv2D(64, (3,3), activation='relu', padding = 'same', input_shape=(100,100,3),kernel_initializer='random_normal', name='conv1'))
model.add(MaxPooling2D(pool_size=(2,2), strides=2, name='maxpool1'))
          
# Set of Layer-2 (Convolutional + MaxPooling)

model.add(Conv2D(128, (3,3), activation='relu', padding = 'same', name='conv2'))
model.add(MaxPooling2D(pool_size=(2,2), strides=2, name='maxpool2'))

# Set of Layer-3 (Convolutional + MaxPooling)

model.add(Conv2D(256, (3,3), activation='relu', padding = 'same', name='conv3'))
model.add(MaxPooling2D(pool_size=(2,2), strides=2, name='maxpool3'))

# Set of Layer-4 (Convolutional + MaxPooling)

model.add(Conv2D(512, (3,3), activation='relu', padding='same', name='conv4'))
model.add(MaxPooling2D(pool_size=(2,2), strides=2, name='maxpool4'))

# Flattening
model.add(Flatten(name='flatten'))

# Fully Connected Neural Network
model.add(Dense(64, activation='relu',  kernel_regularizer=regularizers.L2(4e-3), name='dense1'))
model.add(Dense(128, activation='relu',  kernel_regularizer=regularizers.L2(4e-3), name='dense2'))
model.add(Dense(2, activation='softmax', kernel_regularizer=regularizers.L2(4e-3), name='Output'))

# Compilation of Model
model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=["mae","acc"])
          
model.summary()

# fitting the model
ep=20
GD = model.fit(x=X_train, validation_data=X_valid, epochs=ep, verbose=1)
scores = model.evaluate(x=X_valid)
print(scores)

''' Saving the Model '''

filepath = "/content/drive/Shareddrives/Machine Learning/projectguns/Model"

model.save( filepath, overwrite=True, include_optimizer=True, save_traces=True)

''' Analyzing the performance of the Model '''

plt.style.use("ggplot")
plt.figure()
plt.plot(np.arange(0,ep),GD.history['acc'], Label='Accuracy - Training Data')
plt.plot(np.arange(0,ep),GD.history['val_acc'], Label='Accuracy - Validation Data')
plt.plot(np.arange(0,ep),GD.history['loss'], Label='Loss - Training Data')
plt.plot(np.arange(0,ep),GD.history['val_loss'], Label='Loss - Validation Data')
plt.legend(['Accuracy - Train','Accuracy - Valid','Loss - train','Loss - Valid'])
plt.title('Loss and Accuracy over Datasets')
plt.xlabel('Epoch')
plt.ylabel('Loss & Accuracy')
plt.show()

